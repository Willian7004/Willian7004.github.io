## “服务器繁忙”或成模型能力风向标

出现过服务器繁忙情况的模型中，最出名的是Deepseek R1，该模型是第一个比较实用的开源推理模型，并且也是比较实用的推理模型中第一个免费提供的。发布后一段时间，由于热度上升，出现长时间的服务器繁忙，官方服务几乎在不可用水平。后来在b端和c端都有大部分第三方部署才逐步恢复。这一模型也成为大量开源推理模型的理论和数据基础。

后面出现服务器繁忙的是Kimi K2，虽然没有很多不可用的报告，但也大幅降速且经过一些第三方部署分流，目前还没有完全恢复。这一模型在three.js和html5 canvas等实际编程任务的优化足够深入，不少任务表现不输Claude4 Opus且成本低很多。另外，在开源模型中也首次做到了优秀的agent表现，可以实现长期任务。

在今天（7.29），新发布的GLM4.5也出现服务器繁忙，出现排队时间延长以及429错误。智谱清言只提供GLM4.5 Air且禁用多步搜索，国际版z.ai出现后端问题导致无法加载，7月30日仍有这一问题，推测也有支持全栈开发功能大量开启http服务器的原因。这一模型在前端ui以及connon.js等库的表现进行了深入优化，也是首次在开源模型支持多步多关键词搜索。

这部分模型的提供方都因为模型能力优秀、用户群体大幅扩大导致服务器繁忙，这说明得到用户广泛认可，要求模型在实际应用中有优秀的表现，因此能成为模型能力风向标。不过也有两类不适用的情况：
1. 此前已因繁忙进行扩容已经能够接受较多请求，例如Deepseek以及第三方服务因Deepseek R1扩容后Deepseek R1 0528未遇到大规模繁忙问题。
2. 算力充足的提供方的模型即使用户多也不易繁忙。例如谷歌和X.ai以及提供OpenAI模型的Azure。