## 尝试1.58bit量化

Qwen3 2507以及Qwen3 Coder都只有MoE版本，最小的是30b，cpu推理在长上下文速度下降幅度大。由于MoE模型低比特量化效果较好，决定尝试1.58bit量化，对应gguf版本为IQ1_S。

由于长上下文时kv cache占用显存较多，选择把kv cache放到内存，在8g显存的gpu加载39层，prefill速度大约506token/s，短上下文decode速度17.1token/s，12k上下文decode速度3.9token/s。输出与q4版本不一致但仍然可用。

如果选择把kv cache放到显存，由于加载的模型层数减少，短上下文速度下降较大，长上下文速度优势不明显。但在确保38层加载到gpu的情况下仍然可以把kv cache放到显存，能够选择的上下文长度为8192，prefill速度超过4000token/s，满上下文时decode速度约11token/s。