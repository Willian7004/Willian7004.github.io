## 端侧次旗舰模型的曙光

近期完成了Qwen3 30b 2507以及Qwen3 Coder 30b的部署。按以前的趋势，每一代降低一半参数量，也符合面壁定律。Qwen3算是花了半代把次旗舰dense调整为MoE，虽然在降低参数量上滞后，但带来了更高的推理速度和低比特量化性能。

目前大部分企业以大参数量模型为主，智谱和Meta在成功训练大参数量MoE模型后不再更新小参数量版本，Mistral有小参数量但主要因为预训练模型未能迭代。这虽然使大参数量模型有了更丰富的选择，但也使端侧次旗舰模型丰富度下降。只有Qwen系列保持小参数量模型迭代。

按照面壁定律预测，10月或11月的Qwen4能做到15b次旗舰，能在8g显卡部署q3量化版本。如果结合线性注意力等优化措施，也能在cpu部署时有较好的表现。明年5月前后的Qwen5能做到7.5b次旗舰，能在8g显卡或12g内存的手机部署q4版本、6g显卡部署q3版本、8g内存的手机部署q2版本。这样就实现了绝大多数设备部署端侧次旗舰模型。